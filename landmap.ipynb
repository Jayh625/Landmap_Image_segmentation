{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [모의 경진대회] 토지피복지도 객체 분할\n\n* 이미지 세그멘테이션\n* 담당: 박성호 M","metadata":{"id":"bd75d00d-7b68-45ee-b8a2-89aa88ce6607"}},{"cell_type":"markdown","source":"## 데이터 디렉토리 구조","metadata":{"id":"895492f7-0ddc-437b-939c-da0eabe42b6a"}},{"cell_type":"code","source":"# DATA/\n#   \\_train/\n#        \\_traindf.csv  \n#        \\_images/\n#            \\_xxx.png\n#            \\_yyy.png\n#            \\_zzz.png\n#            \\_...  \n#        \\_masks/\n#            \\_xxx.png\n#            \\_yyy.png\n#            \\_zzz.png\n#            \\_...\n#   \\_test/\n#        \\_sample_submission.csv\n#        \\_testdf.csv\n#        \\_images/\n#            \\_aaa.png  \n#            \\_bbb.png  \n#            \\_...  ","metadata":{"id":"75b185d7-6875-48bd-bae9-279a23d7ddb4","executionInfo":{"status":"ok","timestamp":1669611803414,"user_tz":-540,"elapsed":445,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:24.120431Z","iopub.execute_input":"2022-11-30T12:22:24.120948Z","iopub.status.idle":"2022-11-30T12:22:24.125907Z","shell.execute_reply.started":"2022-11-30T12:22:24.120904Z","shell.execute_reply":"2022-11-30T12:22:24.124848Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## 필수 라이브러리 불러오기","metadata":{"id":"a5f16bf1-a097-47b6-8a19-89155f7d6c09"}},{"cell_type":"code","source":"!pip install segmentation_models_pytorch","metadata":{"id":"4NScJz6c-V5P","executionInfo":{"status":"ok","timestamp":1669611828320,"user_tz":-540,"elapsed":6286,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"outputId":"b44a1971-e619-42f5-94a5-aec2a1e40b26","execution":{"iopub.status.busy":"2022-11-30T12:22:24.127859Z","iopub.execute_input":"2022-11-30T12:22:24.128468Z","iopub.status.idle":"2022-11-30T12:22:41.942311Z","shell.execute_reply.started":"2022-11-30T12:22:24.128425Z","shell.execute_reply":"2022-11-30T12:22:41.941041Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting segmentation_models_pytorch\n  Downloading segmentation_models_pytorch-0.3.0-py3-none-any.whl (97 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m337.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting pretrainedmodels==0.7.4\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting efficientnet-pytorch==0.7.1\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (4.64.0)\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (0.12.0)\nCollecting timm==0.4.12\n  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m940.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (9.1.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.11.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (2.5.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (4.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.21.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.28.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.1.0)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=65cfe6dec777c83d634e810d174704b70304af503ea0183804bc6feffbe563a5\n  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=ffa767b9b47c70861b1c2233661ed5c39c83c8c0739f1d4c257d6e68435045fc\n  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.0 timm-0.4.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport segmentation_models_pytorch as smp\nfrom segmentation_models_pytorch.losses import DiceLoss, SoftBCEWithLogitsLoss, SoftCrossEntropyLoss\n\nimport albumentations as A\nimport cv2\nfrom datetime import datetime, timezone, timedelta","metadata":{"id":"609f5ad9-9f65-4fa6-b987-8fcad156d417","executionInfo":{"status":"ok","timestamp":1669611835038,"user_tz":-540,"elapsed":6722,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:41.945821Z","iopub.execute_input":"2022-11-30T12:22:41.946143Z","iopub.status.idle":"2022-11-30T12:22:46.068506Z","shell.execute_reply.started":"2022-11-30T12:22:41.946111Z","shell.execute_reply":"2022-11-30T12:22:46.067393Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## 하이퍼파라미터 및 기타 인자 설정","metadata":{"id":"3b1220bd-5501-400d-952e-8c185a3d004b"}},{"cell_type":"markdown","source":"#### 데이터 경로","metadata":{"id":"ae2fab69-2736-4486-9754-14ebb2f20018"}},{"cell_type":"code","source":"# 프로젝트 경로\nPROJECT_DIR = '/kaggle/input/landmap-dataset/'\nos.chdir(PROJECT_DIR)\n\n#데이터 경로\nDATA_DIR = os.path.join(PROJECT_DIR) # 모든 데이터가 들어있는 폴더 경로\nTRAIN_DIR = os.path.join(DATA_DIR, 'train') # 학습 데이터가 들어있는 폴더 경로\nTRAIN_IMG_DIR = os.path.join(TRAIN_DIR, 'images') # 학습 이미지가 들어있는 폴더 경로\nTRAIN_MASK_DIR = os.path.join(TRAIN_DIR, 'masks') # 학습 마스크가 들어있는 폴더 경로\nTRAIN_CSV_FILE = os.path.join(TRAIN_DIR, 'traindf.csv') # 학습 이미지와 마스크 이름이 들어있는 CSV 경로","metadata":{"id":"eaf86952-1acf-4b07-87e9-1ce6621e74c0","executionInfo":{"status":"ok","timestamp":1669611835038,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.071116Z","iopub.execute_input":"2022-11-30T12:22:46.072357Z","iopub.status.idle":"2022-11-30T12:22:46.080750Z","shell.execute_reply.started":"2022-11-30T12:22:46.072319Z","shell.execute_reply":"2022-11-30T12:22:46.079559Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 수량 확인:\n- n_train = 3930\n- n_test = 3930","metadata":{"id":"EYMnx6-bmYtA"}},{"cell_type":"code","source":"len(os.listdir(TRAIN_IMG_DIR)) #3930","metadata":{"id":"IavNsHk9B0Zn","executionInfo":{"status":"ok","timestamp":1669611850479,"user_tz":-540,"elapsed":15444,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"outputId":"24edeb0e-8603-42f8-99ab-5c833fbc3aa9","execution":{"iopub.status.busy":"2022-11-30T12:22:46.082206Z","iopub.execute_input":"2022-11-30T12:22:46.082548Z","iopub.status.idle":"2022-11-30T12:22:46.228841Z","shell.execute_reply.started":"2022-11-30T12:22:46.082514Z","shell.execute_reply":"2022-11-30T12:22:46.227877Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"3930"},"metadata":{}}]},{"cell_type":"code","source":"len(os.listdir(TRAIN_MASK_DIR)) #3930","metadata":{"id":"ETP02sKgB5F4","executionInfo":{"status":"ok","timestamp":1669611863491,"user_tz":-540,"elapsed":13014,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"outputId":"9e08216d-363d-437f-9407-8e79e5f3ca87","execution":{"iopub.status.busy":"2022-11-30T12:22:46.230493Z","iopub.execute_input":"2022-11-30T12:22:46.231162Z","iopub.status.idle":"2022-11-30T12:22:46.356333Z","shell.execute_reply.started":"2022-11-30T12:22:46.231126Z","shell.execute_reply":"2022-11-30T12:22:46.355377Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"3930"},"metadata":{}}]},{"cell_type":"markdown","source":"### 결과 저장 경로 설정","metadata":{"id":"5GwfSKc5W1K0"}},{"cell_type":"code","source":"# 시간 고유값 \nkst = timezone(timedelta(hours=9))        \ntrain_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n\n# 기록 경로\nRECORDER_DIR = os.path.join('/kaggle/working/', 'results', 'train', train_serial)\n# 현재 시간 기준 폴더 생성\nos.makedirs(RECORDER_DIR, exist_ok=True)    ","metadata":{"id":"WHoqlnqxW02M","executionInfo":{"status":"ok","timestamp":1669611863952,"user_tz":-540,"elapsed":464,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.357917Z","iopub.execute_input":"2022-11-30T12:22:46.358276Z","iopub.status.idle":"2022-11-30T12:22:46.364741Z","shell.execute_reply.started":"2022-11-30T12:22:46.358241Z","shell.execute_reply":"2022-11-30T12:22:46.363732Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#### 시드 설정","metadata":{"id":"1f2717f1-9c63-469b-8c24-ac63cc9c2e83"}},{"cell_type":"code","source":"RANDOM_SEED = 2022 #랜덤 시드\n\ntorch.manual_seed(RANDOM_SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(RANDOM_SEED)\nrandom.seed(RANDOM_SEED)","metadata":{"id":"578e57e9-2e0c-4802-a7b3-79868119de61","executionInfo":{"status":"ok","timestamp":1669611863953,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.366301Z","iopub.execute_input":"2022-11-30T12:22:46.366957Z","iopub.status.idle":"2022-11-30T12:22:46.375775Z","shell.execute_reply.started":"2022-11-30T12:22:46.366919Z","shell.execute_reply":"2022-11-30T12:22:46.374633Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### 디바이스 설정","metadata":{"id":"21b77e5e-de69-4387-881d-7a223804556a"}},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"41ee20b1-2097-47f5-85bc-010f1674cd5a","executionInfo":{"status":"ok","timestamp":1669611863953,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.380505Z","iopub.execute_input":"2022-11-30T12:22:46.380805Z","iopub.status.idle":"2022-11-30T12:22:46.436090Z","shell.execute_reply.started":"2022-11-30T12:22:46.380779Z","shell.execute_reply":"2022-11-30T12:22:46.434996Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#### 하이퍼파라미터 설정","metadata":{"id":"ecaf0022-98af-4cfd-90e1-8221a31b6c74"}},{"cell_type":"code","source":"EPOCHS = 50\nBATCH_SIZE = 8 #8 # 줄여보자\nLEARNING_RATE = 0.003\nEARLY_STOPPING_PATIENCE = 10\nIMG_SIZE = 512\n\nENCODER = 'timm-efficientnet-b4'# 활용할 인코더 모델\nWEIGHTS = 'imagenet' # Pre-train에 활용된 데이터셋","metadata":{"id":"c6b0a51c-9f25-4627-8d0e-6827aae6e448","executionInfo":{"status":"ok","timestamp":1669611863953,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.440476Z","iopub.execute_input":"2022-11-30T12:22:46.442883Z","iopub.status.idle":"2022-11-30T12:22:46.458688Z","shell.execute_reply.started":"2022-11-30T12:22:46.442846Z","shell.execute_reply":"2022-11-30T12:22:46.457491Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 정의","metadata":{"id":"02c4ca8d-3015-4cb3-bdfe-7c8cd63a7782"}},{"cell_type":"code","source":"class SegDataset(Dataset):\n    def __init__(self, df, augmentations, img_dir, mask_dir):\n        self.df = df # 이미지와 마스크 이름이 저장된 데이터프레임 \n        self.augmentations = augmentations # 학습 전 적용할 augmentation\n        self.img_dir = img_dir # 이미지 폴더 경로\n        self.mask_dir = mask_dir # 마스크 폴더 경로\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        # 데이터 프레임 불러와서 이미지와 마스크 경로 설정\n        row = self.df.iloc[idx] # 데이터프레임 행 불러오기\n        image_path = os.path.join(self.img_dir,row['img'])\n        mask_path = os.path.join(self.mask_dir, row['mask'])\n        \n        # 이미지와 마스크 불러오기\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        mask = np.expand_dims(mask, axis=-1)\n        \n        # Augmentation 적용하기\n        if self.augmentations:\n            data = self.augmentations(image=image, mask=mask)\n            image = data['image']\n            mask = data['mask']\n        \n        # PyTorch 인풋 모양에 맞게 이미지와 마스크 모양 변경\n        image = np.transpose(image, (2,0,1)).astype(np.float32)\n        mask = np.transpose(mask, (2,0,1)).astype(np.float32)\n        \n        # 이미지 Normalization 0~255 픽셀값 --> 0~1 픽셀값\n        image = torch.Tensor(image) / 255.0\n        mask = torch.round(torch.Tensor(mask)/255.0)\n        \n        return image, mask","metadata":{"id":"70b2ad0e-6461-4a55-9557-6d0c5e49678c","executionInfo":{"status":"ok","timestamp":1669611863953,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.466445Z","iopub.execute_input":"2022-11-30T12:22:46.470161Z","iopub.status.idle":"2022-11-30T12:22:46.485625Z","shell.execute_reply.started":"2022-11-30T12:22:46.470122Z","shell.execute_reply":"2022-11-30T12:22:46.484044Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## 모델 정의","metadata":{"id":"f87467f8-d244-43e7-8499-1594335f2f41"}},{"cell_type":"code","source":"class SegModel(nn.Module):\n    def __init__(self):\n        super(SegModel, self).__init__()\n        \n        # Pre-train된 UNET 불러오기\n        self.backbone = smp.Unet(\n            encoder_name = ENCODER, # 인코더 모델 설정\n            encoder_weights = WEIGHTS, # 사전학습 데이터셋 설정\n            in_channels = 3, # 이미지 디멘션 (3 * 512 * 512)\n            classes = 1, # 세그멘테이션 클래스 개수 \n            activation = None # logit 값 불러오기\n        )\n        \n    def forward(self, images):\n        logits = self.backbone(images)\n        \n        return logits","metadata":{"id":"8eafd47a-c32f-4d79-aff6-506a81f5a083","executionInfo":{"status":"ok","timestamp":1669611863954,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.487886Z","iopub.execute_input":"2022-11-30T12:22:46.489472Z","iopub.status.idle":"2022-11-30T12:22:46.514959Z","shell.execute_reply.started":"2022-11-30T12:22:46.489312Z","shell.execute_reply":"2022-11-30T12:22:46.511691Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Utils 정의\n#### Augmentation 함수","metadata":{"id":"3f86cf03-108d-4541-9180-813af657008d"}},{"cell_type":"code","source":"# def get_train_augs():\n#     return A.Compose([\n#         A.Resize(IMG_SIZE, IMG_SIZE), # 이미지 크기 변환\n#         A.HorizontalFlip(p=0.5), # 이미지 좌우반전\n#         A.VerticalFlip(p=0.5) # 이미지 상하반전\n#     ])\n\n# def get_valid_augs():\n#     return A.Compose([\n#         A.Resize(IMG_SIZE, IMG_SIZE)\n#     ])","metadata":{"id":"d2686af4-c4a7-4fde-bb54-1a0ce3f49e72","executionInfo":{"status":"ok","timestamp":1669611863954,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.519238Z","iopub.execute_input":"2022-11-30T12:22:46.521842Z","iopub.status.idle":"2022-11-30T12:22:46.528823Z","shell.execute_reply.started":"2022-11-30T12:22:46.521805Z","shell.execute_reply":"2022-11-30T12:22:46.527528Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def get_train_augs():\n    return A.Compose([\n        A.RandomResizedCrop(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n        A.Rotate(20),\n        A.Flip(),\n        A.Transpose(),\n    A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n    A.Normalize(p=1.0),\n    ], p=1.0)\n\ndef get_valid_augs():\n    return A.Compose([\n    A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n    A.Normalize(p=1.0),\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T12:22:46.531921Z","iopub.execute_input":"2022-11-30T12:22:46.532666Z","iopub.status.idle":"2022-11-30T12:22:46.546142Z","shell.execute_reply.started":"2022-11-30T12:22:46.532621Z","shell.execute_reply":"2022-11-30T12:22:46.544860Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#### Train 함수","metadata":{"id":"540c43c3-e380-4325-bb10-2cd8c62e56d7"}},{"cell_type":"code","source":"def train_fn(dataloader, model, optimizer, loss_fn):\n    model.train()\n    \n    total_loss = 0.0\n    \n    for images,masks in tqdm(dataloader):\n        images = images.to(DEVICE)\n        masks = masks.to(DEVICE)\n        \n        optimizer.zero_grad()\n        logits = model(images)\n        loss = loss_fn(logits, masks)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n    return total_loss/len(dataloader)","metadata":{"id":"e7d69233-2cc3-48c8-a5aa-b17953f6a53b","executionInfo":{"status":"ok","timestamp":1669611863954,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.547960Z","iopub.execute_input":"2022-11-30T12:22:46.548680Z","iopub.status.idle":"2022-11-30T12:22:46.566195Z","shell.execute_reply.started":"2022-11-30T12:22:46.548637Z","shell.execute_reply":"2022-11-30T12:22:46.562664Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"#### Validation 함수","metadata":{"id":"09cbd0cb-f134-47ea-b68e-eef2b2e92ab4"}},{"cell_type":"code","source":"def valid_fn(dataloader, model, loss_fn):\n    model.eval()\n    \n    total_loss = 0.0\n    \n    with torch.no_grad():\n        for images,masks in tqdm(dataloader):\n            images = images.to(DEVICE)\n            masks = masks.to(DEVICE)\n            logits = model(images)\n            loss = loss_fn(logits, masks)\n            total_loss += loss.item()\n    return total_loss/len(dataloader)","metadata":{"id":"46c21e3f-9170-47ea-bf81-a71b01e89efd","executionInfo":{"status":"ok","timestamp":1669611863954,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.568812Z","iopub.execute_input":"2022-11-30T12:22:46.569699Z","iopub.status.idle":"2022-11-30T12:22:46.582140Z","shell.execute_reply.started":"2022-11-30T12:22:46.569664Z","shell.execute_reply":"2022-11-30T12:22:46.581035Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## 모델 학습\n#### Dataset & Dataloader 설정","metadata":{"id":"c71db9f2-fdd0-4b0b-8888-fbcaaa607a58"}},{"cell_type":"code","source":"# 학습 이미지, 마스크 이름 들어있는 CSV 불러와 데이터 프레임으로 저장\nentiredf = pd.read_csv(TRAIN_CSV_FILE)\n\n# Train과 Validation 데이터셋으로 나누기\ntraindf, validdf = train_test_split(entiredf, test_size=0.2)\ntraindf = traindf.reset_index(drop=True)\nvaliddf = validdf.reset_index(drop=True)\n\n# Dataset 및 Dataloader 설정\ntrain_dataset = SegDataset(traindf, get_train_augs(), TRAIN_IMG_DIR, TRAIN_MASK_DIR)\nvalid_dataset = SegDataset(validdf, get_valid_augs(), TRAIN_IMG_DIR, TRAIN_MASK_DIR)\ntrain_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size = BATCH_SIZE)","metadata":{"id":"7ffdac70-018e-4280-bc23-d39eb16d64e2","executionInfo":{"status":"ok","timestamp":1669611863954,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T12:22:46.584139Z","iopub.execute_input":"2022-11-30T12:22:46.584924Z","iopub.status.idle":"2022-11-30T12:22:46.624682Z","shell.execute_reply.started":"2022-11-30T12:22:46.584880Z","shell.execute_reply":"2022-11-30T12:22:46.623328Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"#### 모델과 기타 utils 설정","metadata":{"id":"f6eb184c-a4be-4891-beab-2916870b26f0"}},{"cell_type":"code","source":"class ComboBCEDiceLoss(nn.Module):\n    \"\"\"\n        Combination BinaryCrossEntropy (BCE) and Dice Loss with an optional running mean and loss weighing.\n    \"\"\"\n\n    def __init__(self, use_running_mean=False, bce_weight=1, dice_weight=1, eps=1e-6, gamma=0.9, combined_loss_only=True, **_):\n        \"\"\"\n        :param use_running_mean: - bool (default: False) Whether to accumulate a running mean and add it to the loss with (1-gamma)\n        :param bce_weight: - float (default: 1.0) Weight multiplier for the BCE loss (relative to dice)\n        :param dice_weight: - float (default: 1.0) Weight multiplier for the Dice loss (relative to BCE)\n        :param eps: -\n        :param gamma:\n        :param combined_loss_only: - bool (default: True) whether to return a single combined loss or three separate losses\n        \"\"\"\n\n        super().__init__()\n        '''\n        Note: BCEWithLogitsLoss already performs a torch.sigmoid(pred)\n        before applying BCE!\n        '''\n        self.bce_logits_loss = nn.BCEWithLogitsLoss()\n\n        self.dice_weight = dice_weight\n        self.bce_weight = bce_weight\n        self.eps = eps\n        self.gamma = gamma\n        self.combined_loss_only = combined_loss_only\n\n        self.use_running_mean = use_running_mean\n        self.bce_weight = bce_weight\n        self.dice_weight = dice_weight\n\n        if self.use_running_mean is True:\n            self.register_buffer('running_bce_loss', torch.zeros(1))\n            self.register_buffer('running_dice_loss', torch.zeros(1))\n            self.reset_parameters()\n\n    def to(self, device):\n        super().to(device=device)\n        self.bce_logits_loss.to(device=device)\n\n    def reset_parameters(self):\n        self.running_bce_loss.zero_()\n        self.running_dice_loss.zero_()\n\n    def forward(self, outputs, labels, **_):\n        # inputs and targets are assumed to be BxCxWxH (batch, color, width, height)\n        outputs = outputs.squeeze()       # necessary in case we're dealing with binary segmentation (color dim of 1)\n        if len(outputs.shape) != len(labels.shape):\n            raise AssertionError\n        # assert that B, W and H are the same\n        if outputs.size(-0) != labels.size(-0):\n            raise AssertionError\n        if outputs.size(-1) != labels.size(-1):\n            raise AssertionError\n        if outputs.size(-2) != labels.size(-2):\n            raise AssertionError\n\n        bce_loss = self.bce_logits_loss(outputs, labels)\n\n        dice_target = (labels == 1).float()\n        dice_output = torch.sigmoid(outputs)\n        intersection = (dice_output * dice_target).sum()\n        union = dice_output.sum() + dice_target.sum() + self.eps\n        dice_loss = (-torch.log(2 * intersection / union))\n\n        if self.use_running_mean is False:\n            bmw = self.bce_weight\n            dmw = self.dice_weight\n            # loss += torch.clamp(1 - torch.log(2 * intersection / union),0,100)  * self.dice_weight\n        else:\n            self.running_bce_loss = self.running_bce_loss * self.gamma + bce_loss.data * (1 - self.gamma)\n            self.running_dice_loss = self.running_dice_loss * self.gamma + dice_loss.data * (1 - self.gamma)\n\n            bm = float(self.running_bce_loss)\n            dm = float(self.running_dice_loss)\n\n            bmw = 1 - bm / (bm + dm)\n            dmw = 1 - dm / (bm + dm)\n\n        loss = bce_loss * bmw + dice_loss * dmw\n\n        if self.combined_loss_only:\n            return loss\n        else:\n            return loss, bce_loss, dice_loss","metadata":{"execution":{"iopub.status.busy":"2022-11-30T12:22:46.630018Z","iopub.execute_input":"2022-11-30T12:22:46.632384Z","iopub.status.idle":"2022-11-30T12:22:46.655823Z","shell.execute_reply.started":"2022-11-30T12:22:46.632315Z","shell.execute_reply":"2022-11-30T12:22:46.654910Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#PyTorch\nALPHA = 0.5 # < 0.5 penalises FP more, > 0.5 penalises FN more\nBETA = 0.5\nCE_RATIO = 0.5 #weighted contribution of modified CE loss compared to Dice loss\n\nclass ComboLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(ComboLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA, eps=1e-9):\n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        #True Positives, False Positives & False Negatives\n        intersection = (inputs * targets).sum()    \n        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n\n        inputs = torch.clamp(inputs, eps, 1.0 - eps)       \n        out = - (ALPHA * ((targets * torch.log(inputs)) + ((1 - ALPHA) * (1.0 - targets) * torch.log(1.0 - inputs))))\n        weighted_ce = out.mean(-1)\n        combo = (CE_RATIO * weighted_ce) - ((1 - CE_RATIO) * dice)\n\n        return combo","metadata":{"id":"JFoA6dDi21pn","execution":{"iopub.status.busy":"2022-11-30T12:22:46.660573Z","iopub.execute_input":"2022-11-30T12:22:46.662957Z","iopub.status.idle":"2022-11-30T12:22:46.676026Z","shell.execute_reply.started":"2022-11-30T12:22:46.662921Z","shell.execute_reply":"2022-11-30T12:22:46.675066Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = SegModel().to(DEVICE) # 모델 설정\nloss_fn = DiceLoss(mode = 'binary') # 학습 loss funciton 설정   \n# loss_fn = SoftBCEWithLogitsLoss()\n# loss_fn = SoftCrossEntropyLoss()\n# loss_fn = ComboBCEDiceLoss()  \n\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) # optimizer 설정\n# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n\n# lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[int(EPOCHS * 0.5), int(EPOCHS * 0.75)], gamma=0.1, last_epoch=-1)","metadata":{"id":"d0a25c94-b1d3-4ff6-8483-2ab9d26de630","execution":{"iopub.status.busy":"2022-11-30T12:22:46.681586Z","iopub.execute_input":"2022-11-30T12:22:46.684452Z","iopub.status.idle":"2022-11-30T12:23:03.411035Z","shell.execute_reply.started":"2022-11-30T12:22:46.684382Z","shell.execute_reply":"2022-11-30T12:23:03.410045Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b4_aa-818f208c.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b4_aa-818f208c.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/74.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df4aff7df8e24778bc05a272889330c4"}},"metadata":{}}]},{"cell_type":"markdown","source":"#### Epoch 단위 학습 진행","metadata":{"id":"a5f32e61-19d6-4165-9e09-3c5bdd7b6690"}},{"cell_type":"code","source":"best_loss = np.Inf\n\nfor i in range(EPOCHS):\n    train_loss = train_fn(train_loader, model, optimizer, loss_fn)\n    valid_loss = valid_fn(valid_loader, model, loss_fn)\n    \n    # loss가 감소하면 모델 저장\n    if valid_loss < best_loss:\n        torch.save(model.state_dict(), os.path.join(RECORDER_DIR, \"best-model.pt\"))\n        print('saved model')\n        best_loss = valid_loss\n        print(f\"Epoch: {i+1}, Train Loss: {train_loss} Valid Loss: {valid_loss}\")","metadata":{"id":"17e06473-8ac6-4066-ad8e-505371e08dfa","executionInfo":{"status":"ok","timestamp":1669621698610,"user_tz":-540,"elapsed":9828953,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"outputId":"4fb4b33c-41fd-4249-d640-a8b1de46699c","execution":{"iopub.status.busy":"2022-11-30T12:23:03.412421Z","iopub.execute_input":"2022-11-30T12:23:03.412899Z","iopub.status.idle":"2022-11-30T20:00:01.633215Z","shell.execute_reply.started":"2022-11-30T12:23:03.412856Z","shell.execute_reply":"2022-11-30T20:00:01.632135Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"100%|██████████| 393/393 [09:08<00:00,  1.40s/it]\n100%|██████████| 99/99 [00:31<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 1, Train Loss: 0.34534670894079234 Valid Loss: 0.24856314936069526\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:38<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:25<00:00,  3.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 2, Train Loss: 0.28454103436482164 Valid Loss: 0.21650766242634167\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:41<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:27<00:00,  3.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 3, Train Loss: 0.2588908684466025 Valid Loss: 0.2039755962111733\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:50<00:00,  1.35s/it]\n100%|██████████| 99/99 [00:27<00:00,  3.66it/s]\n100%|██████████| 393/393 [08:44<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.70it/s]\n100%|██████████| 393/393 [08:44<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 6, Train Loss: 0.23034532121726273 Valid Loss: 0.19135756444449376\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:43<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 7, Train Loss: 0.21043017832680816 Valid Loss: 0.1844977850865836\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:43<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.70it/s]\n100%|██████████| 393/393 [08:43<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.73it/s]\n100%|██████████| 393/393 [08:43<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.71it/s]\n100%|██████████| 393/393 [08:42<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.76it/s]\n100%|██████████| 393/393 [08:42<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.72it/s]\n100%|██████████| 393/393 [08:42<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 13, Train Loss: 0.21795644650932486 Valid Loss: 0.17993098979044442\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:41<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 14, Train Loss: 0.18799295467881452 Valid Loss: 0.17453004073615025\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:41<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 15, Train Loss: 0.20196812601793207 Valid Loss: 0.16611725694001322\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.78it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.80it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:25<00:00,  3.82it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 19, Train Loss: 0.19383508892156393 Valid Loss: 0.16459686166108256\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:38<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.76it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.78it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 22, Train Loss: 0.19437373351808115 Valid Loss: 0.16386531639580776\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.77it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.80it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.78it/s]\n100%|██████████| 393/393 [08:38<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 26, Train Loss: 0.18422780646622636 Valid Loss: 0.16186913215752805\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 27, Train Loss: 0.17864705436405637 Valid Loss: 0.15851345869025799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.80it/s]\n100%|██████████| 393/393 [08:40<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.77it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.75it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.77it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.78it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.80it/s]\n100%|██████████| 393/393 [08:38<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.77it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 35, Train Loss: 0.17486182211616264 Valid Loss: 0.15040171567839805\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:25<00:00,  3.81it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.81it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.72it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:25<00:00,  3.81it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.78it/s]\n100%|██████████| 393/393 [08:39<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.78it/s]\n100%|██████████| 393/393 [08:38<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.79it/s]\n100%|██████████| 393/393 [08:40<00:00,  1.32s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.73it/s]\n100%|██████████| 393/393 [08:48<00:00,  1.34s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.72it/s]\n100%|██████████| 393/393 [08:43<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.70it/s]\n100%|██████████| 393/393 [08:44<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.72it/s]\n100%|██████████| 393/393 [08:44<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.69it/s]\n100%|██████████| 393/393 [08:44<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.74it/s]\n100%|██████████| 393/393 [08:42<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"saved model\nEpoch: 49, Train Loss: 0.16029762478578485 Valid Loss: 0.1495883446751219\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 393/393 [08:43<00:00,  1.33s/it]\n100%|██████████| 99/99 [00:26<00:00,  3.70it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 성능 지표\nresnet50 \n- 성능 안좋음\n\neffnet b4 (epoch 50, model 40), so far best model\n- Epoch: 20, Train Loss: 0.13257013098277512 Valid Loss: 0.13606521095892396\n- Epoch: 25, Train Loss: 0.1300631359636632 Valid Loss: 0.13446238065006758\n- Epoch: 40, Train Loss: 0.12472128397939163 Valid Loss: 0.12788941342421253\n- Epoch: 48, Train Loss: 0.11823700175030541 Valid Loss: 0.12040891189767856\n\nvgg19 (epoch 20)\n- Epoch: 19, Train Loss: 0.18212765864743533 Valid Loss: 0.17727654028420498\n\nmobilenet_v2\n- Epoch: 13, Train Loss: 0.18104453669249557 Valid Loss: 0.1695225786681127\n- Epoch: 21, Train Loss: 0.1643344499075989 Valid Loss: 0.16186977516521106\n- Epoch: 26, Train Loss: 0.1639832902803979 Valid Loss: 0.16000752918647998\n- Epoch: 27, Train Loss: 0.1583945419042165 Valid Loss: 0.15862789719995826\n\neffenet b8\n- processing...\n\n","metadata":{}},{"cell_type":"markdown","source":"## 추론","metadata":{"id":"45079578-24cd-4022-bea3-094e1f7ddc6f"}},{"cell_type":"markdown","source":"#### 마스크를 RLE 형태로 변환해주는 함수","metadata":{"id":"858d5a4b-1132-4a3c-b5d8-5ba6d0790d6a"}},{"cell_type":"code","source":"def mask_to_rle(mask):\n    flatten_mask = mask.flatten()\n    if flatten_mask.max() == 0:\n        return f'0 {len(flatten_mask)}'\n    idx = np.where(flatten_mask!=0)[0]\n    steps = idx[1:]-idx[:-1]\n    new_coord = []\n    step_idx = np.where(np.array(steps)!=1)[0]\n    start = np.append(idx[0], idx[step_idx+1])\n    end = np.append(idx[step_idx], idx[-1])\n    length = end - start + 1\n    for i in range(len(start)):\n        new_coord.append(start[i])\n        new_coord.append(length[i])\n    new_coord_str = ' '.join(map(str, new_coord))\n    return new_coord_str","metadata":{"id":"e89b6edd-3b4a-47e9-ac7d-46dbc9554d47","executionInfo":{"status":"ok","timestamp":1669621698611,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T20:00:01.634577Z","iopub.execute_input":"2022-11-30T20:00:01.635656Z","iopub.status.idle":"2022-11-30T20:00:01.644661Z","shell.execute_reply.started":"2022-11-30T20:00:01.635606Z","shell.execute_reply":"2022-11-30T20:00:01.643677Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### Test 데이터셋 불러오기","metadata":{"id":"29918677-0b4d-4d88-95ab-28b459961b7c"}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, df, img_dir):\n        self.df = df\n        self.img_dir = img_dir\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        imname = row['img']\n        image_path = os.path.join(self.img_dir,imname)\n        \n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = np.transpose(image, (2,0,1)).astype(np.float32)\n        image = torch.Tensor(image) / 255.0\n        \n        return image,imname","metadata":{"id":"2d381dfa-582a-440a-855a-a7ba5896f71c","executionInfo":{"status":"ok","timestamp":1669621698611,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T20:00:01.646689Z","iopub.execute_input":"2022-11-30T20:00:01.647060Z","iopub.status.idle":"2022-11-30T20:00:01.659254Z","shell.execute_reply.started":"2022-11-30T20:00:01.647025Z","shell.execute_reply":"2022-11-30T20:00:01.658346Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"#### 경로 및 기타 인자 설정","metadata":{"id":"c238286a-a762-4f01-b6d4-1c4b30d6d297"}},{"cell_type":"code","source":"TEST_DIR = os.path.join(DATA_DIR, 'test') # 테스트 데이터가 들어있는 폴더 경로\nTEST_IMG_DIR = os.path.join(TEST_DIR, 'images') # 테스트 이미지가 들어있는 폴더 경로\nTEST_CSV_FILE = os.path.join(TEST_DIR, 'testdf.csv') # 테스트 이미지 이름이 들어있는 CSV 경로","metadata":{"id":"fd2f468c-3066-4bdd-8cd8-6db5a1807246","executionInfo":{"status":"ok","timestamp":1669621698611,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T20:00:01.664988Z","iopub.execute_input":"2022-11-30T20:00:01.665857Z","iopub.status.idle":"2022-11-30T20:00:01.671207Z","shell.execute_reply.started":"2022-11-30T20:00:01.665826Z","shell.execute_reply":"2022-11-30T20:00:01.670127Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"#### 테스트 Dataset, DataLoader 설정","metadata":{"id":"4a6f1005-184b-43b8-b530-e87c58a3cf6b"}},{"cell_type":"code","source":"testdf = pd.read_csv(TEST_CSV_FILE)\ntest_dataset = TestDataset(testdf, TEST_IMG_DIR)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=1,shuffle=False)","metadata":{"id":"67e19096-8245-4d01-bab6-a9270cfcbc72","executionInfo":{"status":"ok","timestamp":1669621698611,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"execution":{"iopub.status.busy":"2022-11-30T20:00:01.673007Z","iopub.execute_input":"2022-11-30T20:00:01.673510Z","iopub.status.idle":"2022-11-30T20:00:01.691235Z","shell.execute_reply.started":"2022-11-30T20:00:01.673465Z","shell.execute_reply":"2022-11-30T20:00:01.690386Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"#### 최고 성능 모델 불러오기","metadata":{"id":"ce62d43b-7c55-4036-b36d-55e1f2a835c4"}},{"cell_type":"code","source":"model.load_state_dict(torch.load(os.path.join(RECORDER_DIR, 'best-model.pt')))","metadata":{"id":"c016fb2d-2f96-4a36-9832-76f51e64cc18","executionInfo":{"status":"ok","timestamp":1669621699468,"user_tz":-540,"elapsed":860,"user":{"displayName":"Jay H","userId":"04471944603764487605"}},"outputId":"41b6a742-93bd-47cb-836b-af7d14d6c1b0","execution":{"iopub.status.busy":"2022-11-30T20:00:01.692498Z","iopub.execute_input":"2022-11-30T20:00:01.692998Z","iopub.status.idle":"2022-11-30T20:00:01.970549Z","shell.execute_reply.started":"2022-11-30T20:00:01.692962Z","shell.execute_reply":"2022-11-30T20:00:01.969547Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### 추론 진행","metadata":{"id":"cc8ec446-d0ce-4568-99e9-40c9b08486a9"}},{"cell_type":"code","source":"file_list = [] # 이미지 이름 저장할 리스트\npred_list = [] # 마스크 저장할 리스트\nclass_list = [] # 클래스 이름 저장할 리스트 ('building')\n\nmodel.eval()\nwith torch.no_grad():\n    for batch_index, (image,imname) in tqdm(enumerate(test_loader)):\n        image = image.to(DEVICE)\n        logit_mask = model(image)\n        pred_mask = torch.sigmoid(logit_mask) # logit 값을 probability score로 변경\n        pred_mask = (pred_mask > 0.5) * 1.0 # 0.5 이상 확률 가진 픽셀값 1로 변환\n        pred_rle = mask_to_rle(pred_mask.detach().cpu().squeeze(0)) # 마스크를 RLE 형태로 변경\n        pred_list.append(pred_rle)\n        file_list.append(imname[0])\n        class_list.append(\"building\")\n        ","metadata":{"id":"e3070872-23ec-4489-83b3-27e139173639","outputId":"6aed98da-5045-4d0a-90d6-fb21ad5da9d4","execution":{"iopub.status.busy":"2022-11-30T20:00:01.971915Z","iopub.execute_input":"2022-11-30T20:00:01.973218Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"1202it [01:21, 15.25it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 예측 결과 파일 만들기","metadata":{"id":"d00d3a0e-2954-4bc6-94b6-74379222ac45"}},{"cell_type":"code","source":"# 예측 결과 데이터프레임 만들기\nresults = pd.DataFrame({'img_id':file_list,'class':class_list,'prediction':pred_list})\n\n# sample_submission.csv와 같은 형태로 변형\nsampledf = pd.read_csv(os.path.join(TEST_DIR, 'sample_submission.csv'))\nsorter = list(sampledf['img_id'])\nresults = results.set_index('img_id')\nresults = results.loc[sorter].reset_index()\n                       \n# 결과 저장\nresults.to_csv(os.path.join(RECORDER_DIR, 'prediction.csv'), index=False)","metadata":{"id":"0d3687d6-1280-4ea9-b386-c3a2b668c558","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}